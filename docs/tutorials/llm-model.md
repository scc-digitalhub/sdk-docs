# Large Language Models Tutorial

## Overview

Learn how to create and serve Large Language Models (LLMs) using Digitalhub. This tutorial demonstrates working with HuggingFace-compatible models, including direct model serving from the HuggingFace catalog and fine-tuned model deployment.

## What You'll Learn

- Setting up LLM projects in Digitalhub
- Working with HuggingFace model catalog
- Serving pre-trained LLM models
- Deploying fine-tuned models from storage (e.g., S3)
- GPU resource management for LLM workflows
- Using cluster-defined profiles for LLM serving

## Getting Started

1. Import the Jupyter notebook `notebook-llm-model.ipynb` into your Coder instance
2. Execute each cell step by step following the instructions

## Resources

- **üìÅ Source Files**: [digitalhub-tutorials/s5-llm](https://github.com/scc-digitalhub/digitalhub-tutorials/tree/main/s5-llm)
- **ü§ó HuggingFace Documentation**: [Transformers library docs](https://huggingface.co/docs/transformers)
